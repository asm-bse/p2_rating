import os
import requests
import pandas as pd
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from loguru import logger
import json
import time

from base.mes_client import MESClient
from database.postgres_client import PostgreSQLClient

class RatingsSynchronizer(MESClient):
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    
    def __init__(self):
        super().__init__()
        self.api_url = os.getenv('MES_API_URL', 'https://apimes.starline.ru/v1/ratingrest')
        self.page_size = int(os.getenv('MES_PAGE_SIZE', 20))
        self.parallel_requests = int(os.getenv('PARALLEL_REQUESTS', 20))
        self.csv_url = os.getenv('GOOGLE_SHEETS_CSV_URL')
        self.db_client = PostgreSQLClient()


    def validate_configuration(self, source: str) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        if source == 'csv':
            if not self.csv_url:
                logger.error("‚ùå –î–ª—è —Ä–∞–±–æ—Ç—ã —Å CSV –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å GOOGLE_SHEETS_CSV_URL –≤ .env —Ñ–∞–π–ª–µ")
                return False
            logger.info(f"‚úÖ CSV URL –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {self.csv_url}")
        
        elif source == 'api':
            if not self.username or not self.password:
                logger.error("‚ùå –î–ª—è —Ä–∞–±–æ—Ç—ã —Å API –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å MES_USERNAME –∏ MES_PASSWORD –≤ .env —Ñ–∞–π–ª–µ")
                return False
            logger.info(f"‚úÖ API —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {self.username}")
        
        return True
    

    def fetch_page_with_retry(self, page: int) -> Optional[List[Dict]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        for attempt in range(self.max_retries):
            try:
                logger.debug(f"üìÑ –ó–∞–≥—Ä—É–∂–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É {page} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})")
                params = {'page': page, 'size': self.page_size}
                headers = {'Authorization': f'Bearer {self.token}'}
                resp = requests.get(self.api_url, params=params, headers=headers, timeout=15)
                resp.raise_for_status()
                data = resp.json()
                
                # –û–∂–∏–¥–∞–µ–º, —á—Ç–æ –≤ –æ—Ç–≤–µ—Ç–µ –µ—Å—Ç—å –∫–ª—é—á 'items' –∏–ª–∏ —Å–∞–º –æ—Ç–≤–µ—Ç ‚Äî —Å–ø–∏—Å–æ–∫
                items = data.get('items') if isinstance(data, dict) and 'items' in data else data
                
                if items:
                    logger.debug(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(items)} –∑–∞–ø–∏—Å–µ–π")
                else:
                    logger.debug(f"üîö –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –ø—É—Å—Ç–∞—è")
                
                return items
                
            except requests.RequestException as e:
                logger.warning(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}: {e}")
                if attempt < self.max_retries - 1:
                    wait_time = self.retry_delay * (attempt + 1)
                    logger.debug(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {wait_time}s –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π...")
                    time.sleep(wait_time)
                else:
                    logger.error(f"üí• –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É {page} –ø–æ—Å–ª–µ {self.max_retries} –ø–æ–ø—ã—Ç–æ–∫")
                    return None

    def pages_are_identical(self, page1: List[Dict], page2: List[Dict]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç—å –¥–≤—É—Ö —Å—Ç—Ä–∞–Ω–∏—Ü"""
        if not page1 or not page2:
            return False
        if len(page1) != len(page2):
            return False
        return json.dumps(page1, sort_keys=True) == json.dumps(page2, sort_keys=True)

    def fetch_all_ratings(self) -> List[Dict]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –∏–∑ MES API —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
        """
        all_records = []
        page = 1
        previous_page_data = None
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω
        self.token = self.get_auth_token()
        
        logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ MES API...")
        
        while True:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
            page_range = list(range(page, page + self.parallel_requests))
            
            logger.info(f"üì¶ –ó–∞–≥—Ä—É–∂–∞—é –±–∞—Ç—á —Å—Ç—Ä–∞–Ω–∏—Ü: {page_range[0]}-{page_range[-1]} ({len(page_range)} —Å—Ç—Ä–∞–Ω–∏—Ü)")
            
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü
            with ThreadPoolExecutor(max_workers=self.parallel_requests) as executor:
                future_to_page = {
                    executor.submit(self.fetch_page_with_retry, p): p 
                    for p in page_range
                }
                
                batch_results = {}
                completed_count = 0
                
                for future in as_completed(future_to_page):
                    page_num = future_to_page[future]
                    completed_count += 1
                    
                    try:
                        result = future.result()
                        batch_results[page_num] = result
                        logger.debug(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} ({completed_count}/{len(page_range)})")
                    except Exception as e:
                        logger.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
                        batch_results[page_num] = None
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ø–æ—Ä—è–¥–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü
            batch_records = 0
            for p in page_range:
                items = batch_results.get(p)
                
                if items is None:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É {p}")
                    logger.info(f"üìà –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(all_records)}")
                    return all_records
                
                if not items:
                    logger.info(f"üîö –°—Ç—Ä–∞–Ω–∏—Ü—ã –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {p}. –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(all_records)}")
                    return all_records
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ–π
                if previous_page_data and self.pages_are_identical(items, previous_page_data):
                    logger.info(f"üîÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {p} –∏–¥–µ–Ω—Ç–∏—á–Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–π. –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(all_records)}")
                    return all_records
                
                batch_records += len(items)
                all_records.extend(items)
                previous_page_data = items
            
            logger.info(f"‚úÖ –ë–∞—Ç—á –∑–∞–≤–µ—Ä—à–µ–Ω: +{batch_records} –∑–∞–ø–∏—Å–µ–π. –í—Å–µ–≥–æ: {len(all_records)}")
            
            page += self.parallel_requests
            time.sleep(0.1)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏

    def save_to_postgres(self, df: pd.DataFrame, table_name: str = 'mes_ratings'):
        """
        –°–æ—Ö—Ä–∞–Ω–∏—Ç—å DataFrame –≤ PostgreSQL.
        –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É.
        """
        logger.info(f"üíæ –ó–∞–ø–∏—Å—å {len(df)} —Å—Ç—Ä–æ–∫ –≤ —Ç–∞–±–ª–∏—Ü—É '{table_name}' PostgreSQL...")
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º db_client.engine –≤–º–µ—Å—Ç–æ self.engine_pg
            self.db_client.save_table(df, table_name, if_exists='replace')
            logger.info("‚úÖ –ó–∞–ø–∏—Å—å –≤ PostgreSQL –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –≤ PostgreSQL: {e}")
            raise

    def criterion_index_mapping(self, criterion: str) -> int:
        """–ú–∞–ø–ø–∏–Ω–≥ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –Ω–∞ –∏–Ω–¥–µ–∫—Å—ã"""
        mapping = {
            'performance': 1,
            'quality': 2,
            'predlozheniya': 3,
            'can study': 4,
            'can teach': 5,
            'discipline': 6,
            'stage': 7,
            'oborudovanie': 8,
            'own_skills': 9,
            'other_skills': 10,
            'ZOG': 11,
            'academy': 12,
            'points_sum': 13,
            'rank': 14,
            'new_performance': 20,
            'new_quality': 21,
            'discipline_and_oborudovanie': 22,
            'new_skills': 23
        }
        return mapping.get(criterion, 777)

    def load_ratings_from_csv(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –∏–∑ Google Sheets CSV"""
        logger.info('üìä –ó–∞–ø—É—â–µ–Ω–∞ –∑–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞ –∏–∑ CSV')
        
        if not self.csv_url:
            raise ValueError("GOOGLE_SHEETS_CSV_URL –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ .env —Ñ–∞–π–ª.")
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Google Sheets
            logger.info(f"üåê –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ –∏–∑: {self.csv_url}")
            df_rating = pd.read_csv(self.csv_url, skiprows=1)
            logger.info(f'üì• –î–∞–Ω–Ω—ã–µ –∏–∑ Google Sheets –≤—ã–≥—Ä—É–∂–µ–Ω—ã: {len(df_rating)} —Å—Ç—Ä–æ–∫')
            
            # –û—á–∏—Å—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫
            df_rating.columns = df_rating.columns.to_series().apply(lambda x: x.strip())
            logger.debug(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {list(df_rating.columns)}")
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            df_rating = df_rating.fillna(0)
            df_rating = df_rating.drop('fio', axis=1)
            df_rating = pd.melt(
                df_rating, 
                id_vars=['id_employee', 'start_date', 'end_date'], 
                var_name='criterion', 
                value_name='mark'
            )
            logger.info(f"üîÑ –ü–æ—Å–ª–µ melt: {len(df_rating)} —Å—Ç—Ä–æ–∫")
            
            df_rating['mark'] = df_rating['mark'].astype(int)
            df_rating['commentary'] = ''
            df_rating.index.names = ['rating_index']
            
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–∞ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
            df_rating['criterion_index'] = df_rating['criterion'].apply(self.criterion_index_mapping)
            
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
            before_filter = len(df_rating)
            df_rating = df_rating[df_rating['criterion_index'] != 777]
            after_filter = len(df_rating)
            
            if before_filter != after_filter:
                logger.warning(f"üóëÔ∏è  –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {before_filter - after_filter} –∑–∞–ø–∏—Å–µ–π —Å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏")
            
            logger.info(f'‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(df_rating)} –∑–∞–ø–∏—Å–µ–π —Ä–µ–π—Ç–∏–Ω–≥–∞')
            return df_rating
            
        except Exception as e:
            logger.error(f'‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ CSV: {e}')
            raise

    def append_ratings_to_postgres(self, df: pd.DataFrame):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –≤ PostgreSQL —Å –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏"""
        
        logger.info("üîç –ü–æ–ª—É—á–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        try:
            df_rating_old = self.db_client.read_table('mes_ratings')
            max_index = df_rating_old.index.max() if not df_rating_old.empty else 0
            logger.debug(f'üìä –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å: {max_index}')
        except Exception as e:
            logger.warning(f'‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ PostgreSQL: {e}')
            max_index = 0
        
        try:
            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–æ–≤—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤
            df = df.reset_index(drop=True)
            df.index = df.index + max_index + 1
            
            logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {len(df)} –∑–∞–ø–∏—Å–µ–π —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ {max_index + 1}-{max_index + len(df)}...")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ PostgreSQL
            df.to_sql(
                con=self.db_client.engine, 
                name='mes_ratings', 
                if_exists='append', 
                index=True, 
                index_label="rating_index"
            )
            logger.info(f'‚úÖ –†–µ–π—Ç–∏–Ω–≥ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ PostgreSQL: {len(df)} –∑–∞–ø–∏—Å–µ–π')
        except Exception as e:
            logger.error(f'‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ PostgreSQL: {e}')
            raise

    def synchronize(self, source: str = 'api'):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        source: 'api' - –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ MES API, 'csv' - –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ Google Sheets CSV
        """
        logger.info(f"üöÄ –ù–∞—á–∞—Ç–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {source.upper()}")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        if not self.validate_configuration(source):
            raise ValueError(f"–ù–µ–≤–µ—Ä–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {source}")
        
        try:
            if source == 'api':
                # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∑–∞–ø–∏—Å–∏ –∏–∑ API
                logger.info("üì° –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ MES API...")
                records = self.fetch_all_ratings()

                if not records:
                    logger.warning("‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑ API")
                    return

                # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ DataFrame
                logger.info("üîÑ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ DataFrame...")
                df = pd.DataFrame(records)
                logger.info(f"‚úÖ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ DataFrame –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {len(df)} –∑–∞–ø–∏—Å–µ–π")

                # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ Postgres
                self.save_to_postgres(df)
                
            elif source == 'csv':
                # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ CSV
                logger.info("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ CSV...")
                df = self.load_ratings_from_csv()
                
                if df.empty:
                    logger.warning("‚ö†Ô∏è  –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑ CSV")
                    return
                
                # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ PostgreSQL
                logger.info("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ csv_ratings...")
                self.save_to_postgres(df, table_name='csv_ratings')
                
                # –î–æ–±–∞–≤–∏—Ç—å —Å –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏
                logger.info("üìà –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏...")
                self.append_ratings_to_postgres(df)
                
            else:
                raise ValueError("source –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'api' –∏–ª–∏ 'csv'")
                
            logger.success("üéâ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")
            raise