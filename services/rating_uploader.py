import time
import requests
from typing import List, Dict, Tuple, Optional
from loguru import logger
import pandas as pd
import os

from base.mes_client import MESClient
from database.postgres_client import PostgreSQLClient

class RatingUploader(MESClient):
    """–ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –≤ MES API"""
    
    def __init__(self):
        super().__init__()
        self.api_url = "https://apimes.starline.ru/v1/ratingrest/create"
        self.batch_size = int(os.getenv('UPLOAD_BATCH_SIZE', 10))
        self.request_delay = float(os.getenv('REQUEST_DELAY', 0.5))
        self.db_client = PostgreSQLClient()

    def post_rating_to_mes(self, data: Dict, retry_count: int = 0) -> Tuple[bool, Optional[str]]:
        """–û—Ç–ø—Ä–∞–≤–∏—Ç—å –æ–¥–Ω—É –∑–∞–ø–∏—Å—å —Ä–µ–π—Ç–∏–Ω–≥–∞ –≤ MES —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        try:
            # –í—ã–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ (—Å–∫—Ä—ã–≤–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –ø–æ–ª—è)
            debug_data = data.copy()
            if 'commentary' in debug_data and debug_data['commentary'] and len(debug_data['commentary']) > 50:
                debug_data['commentary'] = debug_data['commentary'][:50] + '...'
            logger.debug(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ: {debug_data}")
            
            headers = {
                'Authorization': f'Bearer {self.token}',
                'Content-Type': 'application/json'
            }
            
            response = requests.post(self.api_url, json=data, headers=headers, timeout=15)
            logger.debug(f"–°—Ç–∞—Ç—É—Å-–∫–æ–¥ –æ—Ç–≤–µ—Ç–∞: {response.status_code}")
            
            if response.text:
                try:
                    response_json = response.json()
                    logger.debug(f"–û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞: {response_json}")
                except ValueError:
                    logger.debug(f"–û—Ç–≤–µ—Ç —Å–µ—Ä–≤–µ—Ä–∞ (—Ç–µ–∫—Å—Ç): {response.text}")
            
            response.raise_for_status()
            return True, None
            
        except requests.RequestException as e:
            if retry_count < self.max_retries:
                wait_time = (retry_count + 1) * self.retry_delay
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ ({retry_count + 1}/{self.max_retries}): {e}")
                logger.info(f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {wait_time} —Å–µ–∫...")
                time.sleep(wait_time)
                return self.post_rating_to_mes(data, retry_count + 1)
            else:
                logger.error(f"–ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö: {debug_data}")
                return False, str(e)

    def process_rating_batch(self, batch_data: List[Dict]) -> Tuple[int, int]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤"""
        success_count = 0
        error_count = 0
        
        for data in batch_data:
            success, error = self.post_rating_to_mes(data)
            
            if success:
                success_count += 1
                logger.info(f"‚úÖ –†–µ–π—Ç–∏–Ω–≥ –¥–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ {data['id_employee']} —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω")
            else:
                error_count += 1
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ {data['id_employee']}: {error}")
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            time.sleep(self.request_delay)
        
        return success_count, error_count

    def get_ratings_from_postgres(self, table_name: str = 'csv_ratings') -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –∏–∑ PostgreSQL"""
        try:
            logger.info(f"–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –∏–∑ PostgreSQL —Ç–∞–±–ª–∏—Ü—ã '{table_name}'...")
            df_rating = pd.read_sql(f'SELECT * FROM {table_name}', con=self.db_client.engine)
            
            if df_rating.empty:
                logger.warning(f"–¢–∞–±–ª–∏—Ü–∞ '{table_name}' –ø—É—Å—Ç–∞")
                return df_rating
            
            df_rating = df_rating.sort_values(by='start_date', ascending=False)
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–∏–æ–¥
            latest_period = df_rating['start_date'].max()
            df_latest_ratings = df_rating[df_rating['start_date'] == latest_period]
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(df_latest_ratings)} —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–∏–æ–¥ ({latest_period})")
            return df_latest_ratings
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PostgreSQL: {e}")
            raise

    def prepare_api_data(self, row: pd.Series) -> Dict:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è API"""
        return {
            "rating_index": None,  # –ë—É–¥–µ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω API
            "id_employee": str(int(row['id_employee'])),
            "start_date": str(row['start_date']),
            "end_date": str(row['end_date']),
            "criterion": str(row['criterion']),
            "mark": int(row['mark']),
            "commentary": str(row['commentary']) if pd.notna(row['commentary']) else "",
            "criterion_index": int(row['criterion_index']) if pd.notna(row['criterion_index']) else 0
        }

    def upload_ratings(self, table_name: str = 'csv_ratings', use_batches: bool = True):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤"""
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞
            self.token = self.get_auth_token()
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PostgreSQL
            df_latest_ratings = self.get_ratings_from_postgres(table_name)
            
            if df_latest_ratings.empty:
                logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")
                return
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è API
            api_data_list = []
            for idx, row in df_latest_ratings.iterrows():
                api_data = self.prepare_api_data(row)
                api_data_list.append(api_data)
            
            total_success = 0
            total_errors = 0
            
            logger.info("\n–ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –≤ MES API...")
            
            if use_batches and len(api_data_list) > self.batch_size:
                # –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(api_data_list)} –∑–∞–ø–∏—Å–µ–π –±–∞—Ç—á–∞–º–∏ –ø–æ {self.batch_size}")
                
                # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –±–∞—Ç—á–∏
                batches = [api_data_list[i:i + self.batch_size] 
                            for i in range(0, len(api_data_list), self.batch_size)]
                
                for batch_num, batch in enumerate(batches, 1):
                    logger.info(f"\nüì¶ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ {batch_num}/{len(batches)} ({len(batch)} –∑–∞–ø–∏—Å–µ–π)")
                    
                    batch_success, batch_errors = self.process_rating_batch(batch)
                    total_success += batch_success
                    total_errors += batch_errors
                    
                    logger.info(f"–ë–∞—Ç—á {batch_num}: ‚úÖ {batch_success} —É—Å–ø–µ—à–Ω–æ, ‚ùå {batch_errors} –æ—à–∏–±–æ–∫")
                    
                    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
                    if batch_num < len(batches):
                        time.sleep(1)
            else:
                # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                logger.info("–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–µ–π...")
                for idx, api_data in enumerate(api_data_list, 1):
                    logger.info(f"\n–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞ {idx}/{len(api_data_list)}")
                    
                    success, error = self.post_rating_to_mes(api_data)
                    
                    if success:
                        total_success += 1
                        logger.info(f"‚úÖ –†–µ–π—Ç–∏–Ω–≥ –¥–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ {api_data['id_employee']} —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω ({total_success}/{len(api_data_list)})")
                    else:
                        total_errors += 1
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ {api_data['id_employee']}: {error}")
                    
                    time.sleep(self.request_delay)
            
            # –ò—Ç–æ–≥–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏
            self.print_summary(total_success, total_errors, len(api_data_list))
            
        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤: {e}")
            raise

    def print_summary(self, success_count: int, error_count: int, total_count: int):
        """–í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤ –æ–ø–µ—Ä–∞—Ü–∏–∏"""
        success_rate = (success_count / total_count * 100) if total_count > 0 else 0
        
        logger.info("\n" + "="*50)
        logger.info("üìä –ò—Ç–æ–≥–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏")
        logger.info("="*50)
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {success_count:>5}")
        logger.info(f"‚ùå –û—à–∏–±–æ–∫ –∑–∞–≥—Ä—É–∑–∫–∏:  {error_count:>5}")
        logger.info(f"üìà –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_count:>5}")
        logger.info(f"üéØ –£—Å–ø–µ—à–Ω–æ—Å—Ç—å:       {success_rate:.1f}%")
        logger.info("="*50)