import pandas as pd
import requests
import time
import os
from typing import List, Dict, Optional
from loguru import logger
from sqlalchemy import text

from base.mes_client import MESClient
from database.postgres_client import PostgreSQLClient


class EmployeeService(MESClient):
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤"""
    
    def __init__(self):
        super().__init__()
        self.api_url = "https://apimes.starline.ru/v1/staterest"
        self.additional_data_api_url = "https://apimes.starline.ru/v1/work"
        self.db_client = PostgreSQLClient()
        self.request_delay = float(os.getenv('REQUEST_DELAY', 0.5))
        
    def get_all_employees_from_api(self, max_pages: int = 1000) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏–∑ MES API —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π"""
        logger.info("üîç –ù–∞—á–∏–Ω–∞—é –ø–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏–∑ MES API...")
        
        all_employees = []
        page = 1
        
        try:
            self.token = self.get_auth_token()
            
            while page <= max_pages:
                if page % 10 == 0 or page <= 10:
                    logger.info(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É {page}...")
                
                try:
                    response = requests.get(
                        self.api_url,
                        params={'page': page},
                        headers={'Authorization': f'Bearer {self.token}'},
                        timeout=15
                    )
                    
                    if response.status_code == 200:
                        page_data = response.json()
                        
                        if len(page_data) == 0:
                            logger.info(f"üì≠ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page} –ø—É—Å—Ç–∞—è. –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö.")
                            break
                        
                        existing_ids = {emp['id_employee'] for emp in all_employees}
                        new_employees = [emp for emp in page_data if emp['id_employee'] not in existing_ids]
                        all_employees.extend(new_employees)
                        
                        logger.debug(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –ø–æ–ª—É—á–µ–Ω–æ {len(page_data)} –∑–∞–ø–∏—Å–µ–π, –Ω–æ–≤—ã—Ö: {len(new_employees)}")
                        
                        if len(new_employees) == 0:
                            logger.info(f"üîÑ –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page} —Ç–æ–ª—å–∫–æ –¥—É–±–ª–∏–∫–∞—Ç—ã. –í–æ–∑–º–æ–∂–Ω–æ, –¥–æ—Å—Ç–∏–≥–ª–∏ –∫–æ–Ω—Ü–∞.")
                            break
                            
                    elif response.status_code == 401:
                        logger.warning("üîë –¢–æ–∫–µ–Ω –∏—Å—Ç–µ–∫, –ø–æ–ª—É—á–∞—é –Ω–æ–≤—ã–π...")
                        self.token = self.get_auth_token()
                        continue
                        
                    else:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}: —Å—Ç–∞—Ç—É—Å {response.status_code}")
                        break
                        
                except requests.RequestException as e:
                    logger.error(f"üåê –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
                    if page == 1:
                        raise
                    break
                
                page += 1
                time.sleep(self.request_delay)
                
            logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(all_employees)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤")
            return all_employees
            
        except Exception as e:
            logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {e}")
            raise

    def get_additional_employees_data_from_api(self, max_pages: int = 1000) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏–∑ MES API —Å –≤—ã–±–æ—Ä–æ–º —Å–∞–º—ã—Ö —Å–≤–µ–∂–∏—Ö –∑–∞–ø–∏—Å–µ–π"""
        logger.info("üîç –ù–∞—á–∏–Ω–∞—é –ø–æ–ª—É—á–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏–∑ MES API...")
        
        all_employee_records = []
        page = 1
        seen_page_hashes = set()
        
        try:
            self.token = self.get_auth_token()
            
            while page <= max_pages:
                if page % 10 == 0 or page <= 10:
                    logger.info(f"üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É {page}...")
                
                try:
                    response = requests.get(
                        self.additional_data_api_url,
                        params={'page': page},
                        headers={'Authorization': f'Bearer {self.token}'},
                        timeout=15
                    )
                    
                    if response.status_code == 200:
                        page_data = response.json()
                        
                        if len(page_data) == 0:
                            logger.info(f"üì≠ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page} –ø—É—Å—Ç–∞—è. –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö.")
                            break
                        
                        page_hash = self._get_page_hash(page_data)
                        
                        if page_hash in seen_page_hashes:
                            logger.warning(f"‚ö†Ô∏è –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page} —è–≤–ª—è–µ—Ç—Å—è –¥—É–±–ª–∏–∫–∞—Ç–æ–º (—Ö–µ—à: {page_hash[:8]}...)")
                            logger.info(f"üîÑ –ù–∞–π–¥–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}. –ó–∞–≤–µ—Ä—à–∞–µ–º —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö.")
                            break
                        else:
                            seen_page_hashes.add(page_hash)
                            all_employee_records.extend(page_data)
                            logger.debug(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –ø–æ–ª—É—á–µ–Ω–æ {len(page_data)} –∑–∞–ø–∏—Å–µ–π (—É–Ω–∏–∫–∞–ª—å–Ω–∞—è)")
                            
                    elif response.status_code == 401:
                        logger.warning("üîë –¢–æ–∫–µ–Ω –∏—Å—Ç–µ–∫, –ø–æ–ª—É—á–∞—é –Ω–æ–≤—ã–π...")
                        self.token = self.get_auth_token()
                        continue
                        
                    else:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}: —Å—Ç–∞—Ç—É—Å {response.status_code}")
                        break
                        
                except requests.RequestException as e:
                    logger.error(f"üåê –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}")
                    if page == 1:
                        raise
                    break
                
                page += 1
                time.sleep(self.request_delay)
                
            logger.info(f"üì• –ü–æ–ª—É—á–µ–Ω–æ {len(all_employee_records)} –∑–∞–ø–∏—Å–µ–π –≤—Å–µ–≥–æ —Å {len(seen_page_hashes)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü")
            
            latest_employee_data = self._filter_latest_employee_records(all_employee_records)
            
            logger.info(f"‚úÖ –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–ª—É—á–µ–Ω–æ {len(latest_employee_data)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å —Å–∞–º—ã–º–∏ —Å–≤–µ–∂–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏")
            return latest_employee_data
            
        except Exception as e:
            logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {e}")
            raise

    def _filter_latest_employee_records(self, all_records: List[Dict]) -> List[Dict]:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –∑–∞–ø–∏—Å–∏, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ —Å–≤–µ–∂–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –ø–æ date_work"""
        from datetime import datetime
        
        employee_latest_records = {}
        
        for record in all_records:
            emp_id = record.get('id_employee')
            date_work_str = record.get('date_work')
            
            if not emp_id or not date_work_str:
                logger.debug(f"–ü—Ä–æ–ø—É—Å–∫–∞—é –∑–∞–ø–∏—Å—å –±–µ–∑ id_employee –∏–ª–∏ date_work: {record}")
                continue
            
            try:
                if isinstance(date_work_str, str):
                    if date_work_str == '0000-00-00' or date_work_str.startswith('0000'):
                        date_work = datetime(1900, 1, 1)
                    else:
                        date_work = datetime.strptime(date_work_str[:10], '%Y-%m-%d')
                else:
                    date_work = date_work_str
                
                if (emp_id not in employee_latest_records or 
                    date_work > employee_latest_records[emp_id]['parsed_date']):
                    
                    employee_latest_records[emp_id] = {
                        'data': record,
                        'parsed_date': date_work
                    }
                    
            except (ValueError, TypeError) as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –¥–∞—Ç—ã '{date_work_str}' –¥–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ {emp_id}: {e}")
                if emp_id not in employee_latest_records:
                    employee_latest_records[emp_id] = {
                        'data': record,
                        'parsed_date': datetime(1900, 1, 1)
                    }
        
        latest_records = [emp_data['data'] for emp_data in employee_latest_records.values()]
        
        logger.info(f"üîç –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: –∏–∑ {len(all_records)} –∑–∞–ø–∏—Å–µ–π –≤—ã–±—Ä–∞–Ω–æ {len(latest_records)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö")
        
        return latest_records

    def _get_page_hash(self, page_data: List[Dict]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —Ö–µ—à —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏"""
        import hashlib
        import json
        
        try:
            sorted_data = sorted(page_data, key=lambda x: str(x.get('id_employee', '')))
            hash_string = json.dumps(sorted_data, sort_keys=True, ensure_ascii=False)
            return hashlib.md5(hash_string.encode('utf-8')).hexdigest()
        
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ö–µ—à–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
            ids = [str(item.get('id_employee', '')) for item in page_data[:5]]
            return f"len{len(page_data)}_ids{'_'.join(ids)}"

    def get_current_employees_with_work_data(self, from_api: bool = False) -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å —Ä–∞–±–æ—á–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
        if from_api:
            return self._get_current_employees_from_api()
        else:
            return self._get_current_employees_from_db()

    def _get_current_employees_from_api(self) -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å —Ä–∞–±–æ—á–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ API"""
        try:
            logger.info("üîç –ü–æ–ª—É—á–∞—é –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å —Ä–∞–±–æ—á–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ API...")
            
            employees_data = self.get_all_employees_from_api()
            if not employees_data:
                logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö –∏–∑ API")
                return pd.DataFrame()
            
            df_employees = pd.DataFrame(employees_data)
            df_current = self._filter_current_employees(df_employees)
            
            if df_current.empty:
                return df_current
            
            work_data = self.get_additional_employees_data_from_api()
            if not work_data:
                logger.warning("‚ö†Ô∏è –ù–µ—Ç —Ä–∞–±–æ—á–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ API")
                return df_current[['id_employee', 'fio_employee', 'date_employment_employee']]
            
            return self._merge_employee_work_data(df_current, pd.DataFrame(work_data))
            
        except Exception as e:
            logger.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏–∑ API: {e}")
            raise

    def _get_current_employees_from_db(self) -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å —Ä–∞–±–æ—á–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –ë–î"""
        try:
            logger.info("üîç –ü–æ–ª—É—á–∞—é –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å —Ä–∞–±–æ—á–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –ë–î...")
            
            df_employees = self.get_employees_from_postgres('mes_employees')
            if df_employees.empty:
                logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö –≤ –ë–î")
                return pd.DataFrame()
            
            df_current = self._filter_current_employees(df_employees)
            if df_current.empty:
                return df_current
            
            try:
                df_work = pd.read_sql('SELECT * FROM mes_employees_work', con=self.db_client.engine)
                return self._merge_employee_work_data(df_current, df_work)
                
            except Exception as work_error:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–∞–±–æ—á–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î: {work_error}")
                logger.info("üìù –í–æ–∑–≤—Ä–∞—â–∞—é —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤")
                return df_current[['id_employee', 'fio_employee', 'date_employment_employee']]
            
        except Exception as e:
            logger.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏–∑ –ë–î: {e}")
            raise

    def _filter_current_employees(self, df_employees: pd.DataFrame) -> pd.DataFrame:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å 5-–∑–Ω–∞—á–Ω—ã–º–∏ ID"""
        df_current = df_employees[
            (df_employees['id_employee'].astype(str).str.len() == 5) &
            (df_employees['date_dismissal_employee'].isna() | 
             (df_employees['date_dismissal_employee'] == '') |
             (df_employees['date_dismissal_employee'] == '0000-00-00'))
        ].copy()
        
        if df_current.empty:
            logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å 5-–∑–Ω–∞—á–Ω—ã–º–∏ ID")
        else:
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(df_current)} –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤")
        
        return df_current

    def _merge_employee_work_data(self, df_current: pd.DataFrame, df_work: pd.DataFrame) -> pd.DataFrame:
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å —Ä–∞–±–æ—á–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
        df_result = df_current.merge(
            df_work[['id_employee', 'job_employee', 'subdivision_employee', 
                    'department_employee', 'area_employee']],
            on='id_employee',
            how='left'
        )
        
        columns_to_keep = [
            'id_employee', 'fio_employee', 'date_employment_employee',
            'job_employee', 'subdivision_employee', 'department_employee', 'area_employee'
        ]
        
        df_result = df_result[columns_to_keep]
        
        employees_with_work_data = df_result[df_result['job_employee'].notna()]
        employees_without_work_data = df_result[df_result['job_employee'].isna()]
        
        logger.info(f"   –° —Ä–∞–±–æ—á–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏: {len(employees_with_work_data)}")
        logger.info(f"   –ë–µ–∑ —Ä–∞–±–æ—á–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {len(employees_without_work_data)}")
        
        return df_result

    def export_current_employees(self, filename: str = None, from_api: bool = False) -> str:
        """–≠–∫—Å–ø–æ—Ä—Ç –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ —Å —Ä–∞–±–æ—á–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –≤ CSV"""
        try:
            logger.info("üîç –ù–∞—á–∏–Ω–∞—é —ç–∫—Å–ø–æ—Ä—Ç –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤...")
            
            df_current_employees = self.get_current_employees_with_work_data(from_api=from_api)
            
            if df_current_employees.empty:
                logger.warning("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞")
                return ""
            
            if filename is None:
                from datetime import datetime
                timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M')
                filename = f"exports/current_employees_{timestamp}.csv"
            
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            df_current_employees.to_csv(filename, index=False, encoding='utf-8-sig')
            
            logger.success(f"‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω: {filename}")
            logger.info(f"üìä –í—Å–µ–≥–æ –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {len(df_current_employees)}")
            
            self._log_statistics(df_current_employees)
            
            return filename
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –¥–µ–π—Å—Ç–≤—É—é—â–∏—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {e}")
            raise

    def _log_statistics(self, df: pd.DataFrame):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ DataFrame"""
        if 'subdivision_employee' in df.columns:
            subdivision_stats = df['subdivision_employee'].value_counts()
            logger.info("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è–º:")
            for subdivision, count in subdivision_stats.head(5).items():
                logger.info(f"   {subdivision}: {count}")
        
        if 'job_employee' in df.columns:
            job_stats = df['job_employee'].value_counts()
            logger.info("üìà –¢–æ–ø-5 –¥–æ–ª–∂–Ω–æ—Å—Ç–µ–π:")
            for job, count in job_stats.head(5).items():
                logger.info(f"   {job}: {count}")

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...
    def save_employees_to_postgres(self, employees_data: List[Dict], table_name: str = 'mes_employees') -> bool:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –≤ PostgreSQL"""
        try:
            if not employees_data:
                logger.warning("üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
                return False
            
            logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω—è—é {len(employees_data)} —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü—É '{table_name}'...")
            
            df_employees = pd.DataFrame(employees_data)
            df_employees.to_sql(
                table_name,
                con=self.db_client.engine,
                if_exists='replace',
                index=False,
                method='multi'
            )
            
            logger.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ç–∞–±–ª–∏—Ü—É '{table_name}'")
            return True
            
        except Exception as e:
            logger.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ PostgreSQL: {e}")
            raise

    def save_employees_to_csv(self, employees_data: List[Dict], filename: str = None) -> str:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –≤ CSV"""
        try:
            if not employees_data:
                logger.warning("üì≠ –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
                return ""
            
            if filename is None:
                from datetime import datetime
                timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M")
                filename = f"exports/employees_{timestamp}.csv"
            
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            
            df_employees = pd.DataFrame(employees_data)
            df_employees.to_csv(filename, encoding='utf-8-sig', index=False)
            
            logger.success(f"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ CSV: {e}")
            raise

    def sync_employees(self, save_to_db: bool = True, save_to_csv: bool = True) -> Dict:
        """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤"""
        try:
            logger.info("üîÑ –ù–∞—á–∏–Ω–∞—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤...")
            
            employees_data = self.get_all_employees_from_api()
            
            results = {
                'total_employees': len(employees_data),
                'db_saved': False,
                'csv_file': None
            }
            
            if save_to_db:
                results['db_saved'] = self.save_employees_to_postgres(employees_data)
            
            if save_to_csv:
                results['csv_file'] = self.save_employees_to_csv(employees_data)
            
            logger.success("‚úÖ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            return results
            
        except Exception as e:
            logger.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤: {e}")
            raise

    def get_employees_from_postgres(self, table_name: str = 'mes_employees') -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏–∑ PostgreSQL"""
        try:
            logger.info(f"üîç –ü–æ–ª—É—á–∞—é –¥–∞–Ω–Ω—ã–µ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã '{table_name}'...")
            
            df_employees = pd.read_sql(f'SELECT * FROM {table_name}', con=self.db_client.engine)
            
            logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(df_employees)} –∑–∞–ø–∏—Å–µ–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤")
            return df_employees
            
        except Exception as e:
            if "does not exist" in str(e) or "relation" in str(e):
                logger.warning(f"‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ '{table_name}' –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é.")
                return pd.DataFrame()
            else:
                logger.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PostgreSQL: {e}")
                raise

    def get_employee_statistics(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞–º"""
        try:
            df_employees = self.get_employees_from_postgres()
            
            if df_employees.empty:
                return {'error': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞—Ö. –í—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é: python main_employees.py sync'}
            
            if 'date_dismissal_employee' not in df_employees.columns:
                logger.warning("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ 'date_dismissal_employee' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.")
                stats = {
                    'total_employees': len(df_employees),
                    'active_employees': len(df_employees),
                    'dismissed_employees': 0,
                    'active_percentage': 100.0
                }
            else:
                active_employees = df_employees[df_employees['date_dismissal_employee'].isna()]
                dismissed_employees = df_employees[df_employees['date_dismissal_employee'].notna()]
                
                stats = {
                    'total_employees': len(df_employees),
                    'active_employees': len(active_employees),
                    'dismissed_employees': len(dismissed_employees),
                    'active_percentage': round(len(active_employees) / len(df_employees) * 100, 2)
                }
            
            logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: –≤—Å–µ–≥–æ {stats['total_employees']}, –∞–∫—Ç–∏–≤–Ω—ã—Ö {stats['active_employees']} ({stats['active_percentage']}%)")
            return stats
            
        except Exception as e:
            logger.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            raise